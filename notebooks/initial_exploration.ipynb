{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sp500 open</th>\n",
       "      <th>sp500 high</th>\n",
       "      <th>sp500 low</th>\n",
       "      <th>sp500 close</th>\n",
       "      <th>sp500 volume</th>\n",
       "      <th>sp500 high-low</th>\n",
       "      <th>nasdaq open</th>\n",
       "      <th>nasdaq high</th>\n",
       "      <th>nasdaq low</th>\n",
       "      <th>...</th>\n",
       "      <th>palladium high</th>\n",
       "      <th>palladium low</th>\n",
       "      <th>palladium close</th>\n",
       "      <th>palladium volume</th>\n",
       "      <th>palladium high-low</th>\n",
       "      <th>gold open</th>\n",
       "      <th>gold high</th>\n",
       "      <th>gold low</th>\n",
       "      <th>gold close</th>\n",
       "      <th>gold volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-14</td>\n",
       "      <td>114.49</td>\n",
       "      <td>115.14</td>\n",
       "      <td>114.42</td>\n",
       "      <td>114.93</td>\n",
       "      <td>115646960.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>46.26</td>\n",
       "      <td>46.520</td>\n",
       "      <td>46.22</td>\n",
       "      <td>...</td>\n",
       "      <td>45.02</td>\n",
       "      <td>43.86</td>\n",
       "      <td>44.84</td>\n",
       "      <td>364528.0</td>\n",
       "      <td>1.16</td>\n",
       "      <td>111.51</td>\n",
       "      <td>112.37</td>\n",
       "      <td>110.79</td>\n",
       "      <td>112.03</td>\n",
       "      <td>18305238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-15</td>\n",
       "      <td>114.73</td>\n",
       "      <td>114.84</td>\n",
       "      <td>113.20</td>\n",
       "      <td>113.64</td>\n",
       "      <td>212252769.0</td>\n",
       "      <td>1.64</td>\n",
       "      <td>46.46</td>\n",
       "      <td>46.550</td>\n",
       "      <td>45.65</td>\n",
       "      <td>...</td>\n",
       "      <td>45.76</td>\n",
       "      <td>44.40</td>\n",
       "      <td>45.76</td>\n",
       "      <td>442210.0</td>\n",
       "      <td>1.36</td>\n",
       "      <td>111.35</td>\n",
       "      <td>112.01</td>\n",
       "      <td>110.38</td>\n",
       "      <td>110.86</td>\n",
       "      <td>18000724.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-19</td>\n",
       "      <td>113.62</td>\n",
       "      <td>115.13</td>\n",
       "      <td>113.59</td>\n",
       "      <td>115.06</td>\n",
       "      <td>138671890.0</td>\n",
       "      <td>1.54</td>\n",
       "      <td>45.96</td>\n",
       "      <td>46.640</td>\n",
       "      <td>45.95</td>\n",
       "      <td>...</td>\n",
       "      <td>47.08</td>\n",
       "      <td>45.70</td>\n",
       "      <td>46.94</td>\n",
       "      <td>629150.0</td>\n",
       "      <td>1.38</td>\n",
       "      <td>110.95</td>\n",
       "      <td>111.75</td>\n",
       "      <td>110.83</td>\n",
       "      <td>111.52</td>\n",
       "      <td>10467927.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-20</td>\n",
       "      <td>114.28</td>\n",
       "      <td>114.45</td>\n",
       "      <td>112.98</td>\n",
       "      <td>113.89</td>\n",
       "      <td>216330645.0</td>\n",
       "      <td>1.47</td>\n",
       "      <td>46.27</td>\n",
       "      <td>46.604</td>\n",
       "      <td>45.43</td>\n",
       "      <td>...</td>\n",
       "      <td>47.31</td>\n",
       "      <td>45.17</td>\n",
       "      <td>47.05</td>\n",
       "      <td>643198.0</td>\n",
       "      <td>2.14</td>\n",
       "      <td>109.97</td>\n",
       "      <td>110.05</td>\n",
       "      <td>108.46</td>\n",
       "      <td>108.94</td>\n",
       "      <td>17534231.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  sp500 open  sp500 high  sp500 low  sp500 close  sp500 volume  \\\n",
       "0  2010-01-14      114.49      115.14     114.42       114.93   115646960.0   \n",
       "1  2010-01-15      114.73      114.84     113.20       113.64   212252769.0   \n",
       "2  2010-01-18         NaN         NaN        NaN          NaN           NaN   \n",
       "3  2010-01-19      113.62      115.13     113.59       115.06   138671890.0   \n",
       "4  2010-01-20      114.28      114.45     112.98       113.89   216330645.0   \n",
       "\n",
       "   sp500 high-low  nasdaq open  nasdaq high  nasdaq low  ...  palladium high  \\\n",
       "0            0.72        46.26       46.520       46.22  ...           45.02   \n",
       "1            1.64        46.46       46.550       45.65  ...           45.76   \n",
       "2             NaN          NaN          NaN         NaN  ...             NaN   \n",
       "3            1.54        45.96       46.640       45.95  ...           47.08   \n",
       "4            1.47        46.27       46.604       45.43  ...           47.31   \n",
       "\n",
       "   palladium low  palladium close  palladium volume  palladium high-low  \\\n",
       "0          43.86            44.84          364528.0                1.16   \n",
       "1          44.40            45.76          442210.0                1.36   \n",
       "2            NaN              NaN               NaN                 NaN   \n",
       "3          45.70            46.94          629150.0                1.38   \n",
       "4          45.17            47.05          643198.0                2.14   \n",
       "\n",
       "   gold open  gold high  gold low  gold close  gold volume  \n",
       "0     111.51     112.37    110.79      112.03   18305238.0  \n",
       "1     111.35     112.01    110.38      110.86   18000724.0  \n",
       "2        NaN        NaN       NaN         NaN          NaN  \n",
       "3     110.95     111.75    110.83      111.52   10467927.0  \n",
       "4     109.97     110.05    108.46      108.94   17534231.0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "import os\n",
    "project_root = os.path.abspath(\"..\")  # Add the project root to the Python path\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "    sys.path.append(os.path.abspath('../src/'))\n",
    "\n",
    "from src.data_preprocessing import DataPreprocessor\n",
    "\n",
    "\n",
    "file_path = (\n",
    "    \"../data/raw/financial_regression.csv\"  # Adjust the path based on your directory structure\n",
    ")\n",
    "data_preprocessor = DataPreprocessor(file_path)\n",
    "df = data_preprocessor.load_data(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_backfill = ['us_rates_%','CPI','GDP']\n",
    "# df_back = df\n",
    "# df_back[columns_backfill] = df_back[columns_backfill].fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_back.loc[:,('date','us_rates_%','CPI','GDP')].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                   object\n",
       "sp500 open            float64\n",
       "sp500 high            float64\n",
       "sp500 low             float64\n",
       "sp500 close           float64\n",
       "sp500 volume          float64\n",
       "sp500 high-low        float64\n",
       "nasdaq open           float64\n",
       "nasdaq high           float64\n",
       "nasdaq low            float64\n",
       "nasdaq close          float64\n",
       "nasdaq volume         float64\n",
       "nasdaq high-low       float64\n",
       "us_rates_%            float64\n",
       "CPI                   float64\n",
       "usd_chf               float64\n",
       "eur_usd               float64\n",
       "GDP                   float64\n",
       "silver open           float64\n",
       "silver high           float64\n",
       "silver low            float64\n",
       "silver close          float64\n",
       "silver volume         float64\n",
       "silver high-low       float64\n",
       "oil open              float64\n",
       "oil high              float64\n",
       "oil low               float64\n",
       "oil close             float64\n",
       "oil volume            float64\n",
       "oil high-low          float64\n",
       "platinum open         float64\n",
       "platinum high         float64\n",
       "platinum low          float64\n",
       "platinum close        float64\n",
       "platinum volume       float64\n",
       "platinum high-low     float64\n",
       "palladium open        float64\n",
       "palladium high        float64\n",
       "palladium low         float64\n",
       "palladium close       float64\n",
       "palladium volume      float64\n",
       "palladium high-low    float64\n",
       "gold open             float64\n",
       "gold high             float64\n",
       "gold low              float64\n",
       "gold close            float64\n",
       "gold volume           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_interploate = ['us_rates_%','CPI','GDP','usd_chf','eur_usd']\n",
    "df['date']  = pd.to_datetime(df['date'])\n",
    "df.set_index('date', inplace=True)\n",
    "df[columns_to_interploate] = df[columns_to_interploate].interpolate(method='time')\n",
    "df.reset_index(inplace=True)\n",
    "df[columns_to_interploate] = df[columns_to_interploate].fillna(method='bfill')\n",
    "\n",
    "#df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[columns_to_interploate] = df[columns_to_interploate].fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>us_rates_%</th>\n",
       "      <th>CPI</th>\n",
       "      <th>GDP</th>\n",
       "      <th>usd_chf</th>\n",
       "      <th>eur_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.130000</td>\n",
       "      <td>217.281000</td>\n",
       "      <td>14980.193</td>\n",
       "      <td>1.0206</td>\n",
       "      <td>1.447800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.130000</td>\n",
       "      <td>217.281000</td>\n",
       "      <td>14980.193</td>\n",
       "      <td>1.0264</td>\n",
       "      <td>1.437600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.130000</td>\n",
       "      <td>217.281000</td>\n",
       "      <td>14980.193</td>\n",
       "      <td>1.0321</td>\n",
       "      <td>1.429575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.130000</td>\n",
       "      <td>217.281000</td>\n",
       "      <td>14980.193</td>\n",
       "      <td>1.0340</td>\n",
       "      <td>1.426900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.130000</td>\n",
       "      <td>217.281000</td>\n",
       "      <td>14980.193</td>\n",
       "      <td>1.0453</td>\n",
       "      <td>1.409400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.130000</td>\n",
       "      <td>217.281000</td>\n",
       "      <td>14980.193</td>\n",
       "      <td>1.0426</td>\n",
       "      <td>1.410600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.130000</td>\n",
       "      <td>217.281000</td>\n",
       "      <td>14980.193</td>\n",
       "      <td>1.0400</td>\n",
       "      <td>1.415400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.130000</td>\n",
       "      <td>217.281000</td>\n",
       "      <td>14980.193</td>\n",
       "      <td>1.0403</td>\n",
       "      <td>1.414600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.130000</td>\n",
       "      <td>217.281000</td>\n",
       "      <td>14980.193</td>\n",
       "      <td>1.0466</td>\n",
       "      <td>1.406300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.130000</td>\n",
       "      <td>217.281000</td>\n",
       "      <td>14980.193</td>\n",
       "      <td>1.0472</td>\n",
       "      <td>1.405300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.130000</td>\n",
       "      <td>217.281000</td>\n",
       "      <td>14980.193</td>\n",
       "      <td>1.0517</td>\n",
       "      <td>1.399300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.130000</td>\n",
       "      <td>217.281000</td>\n",
       "      <td>14980.193</td>\n",
       "      <td>1.0557</td>\n",
       "      <td>1.387000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.130000</td>\n",
       "      <td>217.281000</td>\n",
       "      <td>14980.193</td>\n",
       "      <td>1.0586</td>\n",
       "      <td>1.390400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.131071</td>\n",
       "      <td>217.283571</td>\n",
       "      <td>14980.193</td>\n",
       "      <td>1.0557</td>\n",
       "      <td>1.395500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.132143</td>\n",
       "      <td>217.286143</td>\n",
       "      <td>14980.193</td>\n",
       "      <td>1.0590</td>\n",
       "      <td>1.390700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.133214</td>\n",
       "      <td>217.288714</td>\n",
       "      <td>14980.193</td>\n",
       "      <td>1.0655</td>\n",
       "      <td>1.375900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.134286</td>\n",
       "      <td>217.291286</td>\n",
       "      <td>14980.193</td>\n",
       "      <td>1.0779</td>\n",
       "      <td>1.360800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.137500</td>\n",
       "      <td>217.299000</td>\n",
       "      <td>14980.193</td>\n",
       "      <td>1.0696</td>\n",
       "      <td>1.369900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.138571</td>\n",
       "      <td>217.301571</td>\n",
       "      <td>14980.193</td>\n",
       "      <td>1.0641</td>\n",
       "      <td>1.379500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.139643</td>\n",
       "      <td>217.304143</td>\n",
       "      <td>14980.193</td>\n",
       "      <td>1.0682</td>\n",
       "      <td>1.372200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.140714</td>\n",
       "      <td>217.306714</td>\n",
       "      <td>14980.193</td>\n",
       "      <td>1.0747</td>\n",
       "      <td>1.364000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    us_rates_%         CPI        GDP  usd_chf   eur_usd\n",
       "0     0.130000  217.281000  14980.193   1.0206  1.447800\n",
       "1     0.130000  217.281000  14980.193   1.0264  1.437600\n",
       "2     0.130000  217.281000  14980.193   1.0321  1.429575\n",
       "3     0.130000  217.281000  14980.193   1.0340  1.426900\n",
       "4     0.130000  217.281000  14980.193   1.0453  1.409400\n",
       "5     0.130000  217.281000  14980.193   1.0426  1.410600\n",
       "6     0.130000  217.281000  14980.193   1.0400  1.415400\n",
       "7     0.130000  217.281000  14980.193   1.0403  1.414600\n",
       "8     0.130000  217.281000  14980.193   1.0466  1.406300\n",
       "9     0.130000  217.281000  14980.193   1.0472  1.405300\n",
       "10    0.130000  217.281000  14980.193   1.0517  1.399300\n",
       "11    0.130000  217.281000  14980.193   1.0557  1.387000\n",
       "12    0.130000  217.281000  14980.193   1.0586  1.390400\n",
       "13    0.131071  217.283571  14980.193   1.0557  1.395500\n",
       "14    0.132143  217.286143  14980.193   1.0590  1.390700\n",
       "15    0.133214  217.288714  14980.193   1.0655  1.375900\n",
       "16    0.134286  217.291286  14980.193   1.0779  1.360800\n",
       "17    0.137500  217.299000  14980.193   1.0696  1.369900\n",
       "18    0.138571  217.301571  14980.193   1.0641  1.379500\n",
       "19    0.139643  217.304143  14980.193   1.0682  1.372200\n",
       "20    0.140714  217.306714  14980.193   1.0747  1.364000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# df.head()\n",
    "df.loc[0:20,('us_rates_%','CPI','GDP','usd_chf','eur_usd')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['date','gold close'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                  0\n",
       "sp500 open            0\n",
       "sp500 high            0\n",
       "sp500 low             0\n",
       "sp500 close           0\n",
       "sp500 volume          0\n",
       "sp500 high-low        0\n",
       "nasdaq open           0\n",
       "nasdaq high           0\n",
       "nasdaq low            0\n",
       "nasdaq close          0\n",
       "nasdaq volume         0\n",
       "nasdaq high-low       0\n",
       "us_rates_%            0\n",
       "CPI                   0\n",
       "usd_chf               0\n",
       "eur_usd               0\n",
       "GDP                   0\n",
       "silver open           0\n",
       "silver high           0\n",
       "silver low            0\n",
       "silver close          0\n",
       "silver volume         0\n",
       "silver high-low       0\n",
       "oil open              0\n",
       "oil high              0\n",
       "oil low               0\n",
       "oil close             0\n",
       "oil volume            0\n",
       "oil high-low          0\n",
       "platinum open         0\n",
       "platinum high         0\n",
       "platinum low          0\n",
       "platinum close        0\n",
       "platinum volume       0\n",
       "platinum high-low     0\n",
       "palladium open        0\n",
       "palladium high        0\n",
       "palladium low         0\n",
       "palladium close       0\n",
       "palladium volume      0\n",
       "palladium high-low    0\n",
       "gold open             0\n",
       "gold high             0\n",
       "gold low              0\n",
       "gold close            0\n",
       "gold volume           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicates = df['date'].duplicated().sum()\n",
    "duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sp500 open</th>\n",
       "      <th>sp500 high</th>\n",
       "      <th>sp500 low</th>\n",
       "      <th>sp500 close</th>\n",
       "      <th>sp500 volume</th>\n",
       "      <th>sp500 high-low</th>\n",
       "      <th>nasdaq open</th>\n",
       "      <th>nasdaq high</th>\n",
       "      <th>nasdaq low</th>\n",
       "      <th>...</th>\n",
       "      <th>palladium high</th>\n",
       "      <th>palladium low</th>\n",
       "      <th>palladium close</th>\n",
       "      <th>palladium volume</th>\n",
       "      <th>palladium high-low</th>\n",
       "      <th>gold open</th>\n",
       "      <th>gold high</th>\n",
       "      <th>gold low</th>\n",
       "      <th>gold close</th>\n",
       "      <th>gold volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-14</td>\n",
       "      <td>114.49</td>\n",
       "      <td>115.14</td>\n",
       "      <td>114.42</td>\n",
       "      <td>114.93</td>\n",
       "      <td>115646960.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>46.26</td>\n",
       "      <td>46.520</td>\n",
       "      <td>46.22</td>\n",
       "      <td>...</td>\n",
       "      <td>45.02</td>\n",
       "      <td>43.86</td>\n",
       "      <td>44.84</td>\n",
       "      <td>364528.0</td>\n",
       "      <td>1.16</td>\n",
       "      <td>111.51</td>\n",
       "      <td>112.37</td>\n",
       "      <td>110.79</td>\n",
       "      <td>112.03</td>\n",
       "      <td>18305238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-15</td>\n",
       "      <td>114.73</td>\n",
       "      <td>114.84</td>\n",
       "      <td>113.20</td>\n",
       "      <td>113.64</td>\n",
       "      <td>212252769.0</td>\n",
       "      <td>1.64</td>\n",
       "      <td>46.46</td>\n",
       "      <td>46.550</td>\n",
       "      <td>45.65</td>\n",
       "      <td>...</td>\n",
       "      <td>45.76</td>\n",
       "      <td>44.40</td>\n",
       "      <td>45.76</td>\n",
       "      <td>442210.0</td>\n",
       "      <td>1.36</td>\n",
       "      <td>111.35</td>\n",
       "      <td>112.01</td>\n",
       "      <td>110.38</td>\n",
       "      <td>110.86</td>\n",
       "      <td>18000724.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-19</td>\n",
       "      <td>113.62</td>\n",
       "      <td>115.13</td>\n",
       "      <td>113.59</td>\n",
       "      <td>115.06</td>\n",
       "      <td>138671890.0</td>\n",
       "      <td>1.54</td>\n",
       "      <td>45.96</td>\n",
       "      <td>46.640</td>\n",
       "      <td>45.95</td>\n",
       "      <td>...</td>\n",
       "      <td>47.08</td>\n",
       "      <td>45.70</td>\n",
       "      <td>46.94</td>\n",
       "      <td>629150.0</td>\n",
       "      <td>1.38</td>\n",
       "      <td>110.95</td>\n",
       "      <td>111.75</td>\n",
       "      <td>110.83</td>\n",
       "      <td>111.52</td>\n",
       "      <td>10467927.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-20</td>\n",
       "      <td>114.28</td>\n",
       "      <td>114.45</td>\n",
       "      <td>112.98</td>\n",
       "      <td>113.89</td>\n",
       "      <td>216330645.0</td>\n",
       "      <td>1.47</td>\n",
       "      <td>46.27</td>\n",
       "      <td>46.604</td>\n",
       "      <td>45.43</td>\n",
       "      <td>...</td>\n",
       "      <td>47.31</td>\n",
       "      <td>45.17</td>\n",
       "      <td>47.05</td>\n",
       "      <td>643198.0</td>\n",
       "      <td>2.14</td>\n",
       "      <td>109.97</td>\n",
       "      <td>110.05</td>\n",
       "      <td>108.46</td>\n",
       "      <td>108.94</td>\n",
       "      <td>17534231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2010-01-21</td>\n",
       "      <td>113.92</td>\n",
       "      <td>114.27</td>\n",
       "      <td>111.56</td>\n",
       "      <td>111.70</td>\n",
       "      <td>344747028.0</td>\n",
       "      <td>2.71</td>\n",
       "      <td>46.06</td>\n",
       "      <td>46.350</td>\n",
       "      <td>45.30</td>\n",
       "      <td>...</td>\n",
       "      <td>46.98</td>\n",
       "      <td>45.07</td>\n",
       "      <td>45.30</td>\n",
       "      <td>388457.0</td>\n",
       "      <td>1.91</td>\n",
       "      <td>108.48</td>\n",
       "      <td>108.78</td>\n",
       "      <td>106.61</td>\n",
       "      <td>107.37</td>\n",
       "      <td>25747831.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  sp500 open  sp500 high  sp500 low  sp500 close  sp500 volume  \\\n",
       "0 2010-01-14      114.49      115.14     114.42       114.93   115646960.0   \n",
       "1 2010-01-15      114.73      114.84     113.20       113.64   212252769.0   \n",
       "3 2010-01-19      113.62      115.13     113.59       115.06   138671890.0   \n",
       "4 2010-01-20      114.28      114.45     112.98       113.89   216330645.0   \n",
       "5 2010-01-21      113.92      114.27     111.56       111.70   344747028.0   \n",
       "\n",
       "   sp500 high-low  nasdaq open  nasdaq high  nasdaq low  ...  palladium high  \\\n",
       "0            0.72        46.26       46.520       46.22  ...           45.02   \n",
       "1            1.64        46.46       46.550       45.65  ...           45.76   \n",
       "3            1.54        45.96       46.640       45.95  ...           47.08   \n",
       "4            1.47        46.27       46.604       45.43  ...           47.31   \n",
       "5            2.71        46.06       46.350       45.30  ...           46.98   \n",
       "\n",
       "   palladium low  palladium close  palladium volume  palladium high-low  \\\n",
       "0          43.86            44.84          364528.0                1.16   \n",
       "1          44.40            45.76          442210.0                1.36   \n",
       "3          45.70            46.94          629150.0                1.38   \n",
       "4          45.17            47.05          643198.0                2.14   \n",
       "5          45.07            45.30          388457.0                1.91   \n",
       "\n",
       "   gold open  gold high  gold low  gold close  gold volume  \n",
       "0     111.51     112.37    110.79      112.03   18305238.0  \n",
       "1     111.35     112.01    110.38      110.86   18000724.0  \n",
       "3     110.95     111.75    110.83      111.52   10467927.0  \n",
       "4     109.97     110.05    108.46      108.94   17534231.0  \n",
       "5     108.48     108.78    106.61      107.37   25747831.0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>us_rates_%</th>\n",
       "      <th>CPI</th>\n",
       "      <th>GDP</th>\n",
       "      <th>usd_chf</th>\n",
       "      <th>eur_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.180000</td>\n",
       "      <td>217.212533</td>\n",
       "      <td>15090.167374</td>\n",
       "      <td>1.1575</td>\n",
       "      <td>1.2206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.180000</td>\n",
       "      <td>217.226067</td>\n",
       "      <td>15091.941154</td>\n",
       "      <td>1.1540</td>\n",
       "      <td>1.2193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.180000</td>\n",
       "      <td>217.239600</td>\n",
       "      <td>15093.714934</td>\n",
       "      <td>1.1614</td>\n",
       "      <td>1.1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.180000</td>\n",
       "      <td>217.280200</td>\n",
       "      <td>15099.036275</td>\n",
       "      <td>1.1613</td>\n",
       "      <td>1.1959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.180000</td>\n",
       "      <td>217.293733</td>\n",
       "      <td>15100.810055</td>\n",
       "      <td>1.1510</td>\n",
       "      <td>1.1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.180000</td>\n",
       "      <td>217.307267</td>\n",
       "      <td>15102.583835</td>\n",
       "      <td>1.1455</td>\n",
       "      <td>1.2045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.180000</td>\n",
       "      <td>217.320800</td>\n",
       "      <td>15104.357615</td>\n",
       "      <td>1.1418</td>\n",
       "      <td>1.2111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.180000</td>\n",
       "      <td>217.334333</td>\n",
       "      <td>15106.131396</td>\n",
       "      <td>1.1521</td>\n",
       "      <td>1.2077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.180000</td>\n",
       "      <td>217.374933</td>\n",
       "      <td>15111.452736</td>\n",
       "      <td>1.1378</td>\n",
       "      <td>1.2277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.180000</td>\n",
       "      <td>217.388467</td>\n",
       "      <td>15113.226516</td>\n",
       "      <td>1.1310</td>\n",
       "      <td>1.2327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.180000</td>\n",
       "      <td>217.402000</td>\n",
       "      <td>15115.000297</td>\n",
       "      <td>1.1267</td>\n",
       "      <td>1.2323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.180000</td>\n",
       "      <td>217.415533</td>\n",
       "      <td>15116.774077</td>\n",
       "      <td>1.1137</td>\n",
       "      <td>1.2365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.180000</td>\n",
       "      <td>217.429067</td>\n",
       "      <td>15118.547857</td>\n",
       "      <td>1.1107</td>\n",
       "      <td>1.2360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.180000</td>\n",
       "      <td>217.469667</td>\n",
       "      <td>15123.869198</td>\n",
       "      <td>1.1080</td>\n",
       "      <td>1.2385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.180000</td>\n",
       "      <td>217.483200</td>\n",
       "      <td>15125.642978</td>\n",
       "      <td>1.1047</td>\n",
       "      <td>1.2303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.180000</td>\n",
       "      <td>217.496733</td>\n",
       "      <td>15127.416758</td>\n",
       "      <td>1.1053</td>\n",
       "      <td>1.2310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.180000</td>\n",
       "      <td>217.510267</td>\n",
       "      <td>15129.190538</td>\n",
       "      <td>1.1048</td>\n",
       "      <td>1.2288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.180000</td>\n",
       "      <td>217.523800</td>\n",
       "      <td>15130.964319</td>\n",
       "      <td>1.0937</td>\n",
       "      <td>1.2332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.180000</td>\n",
       "      <td>217.564400</td>\n",
       "      <td>15136.285659</td>\n",
       "      <td>1.0860</td>\n",
       "      <td>1.2316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.180000</td>\n",
       "      <td>217.577933</td>\n",
       "      <td>15138.059440</td>\n",
       "      <td>1.0810</td>\n",
       "      <td>1.2187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.180000</td>\n",
       "      <td>217.591467</td>\n",
       "      <td>15139.833220</td>\n",
       "      <td>1.0774</td>\n",
       "      <td>1.2291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.180000</td>\n",
       "      <td>217.605000</td>\n",
       "      <td>15141.607000</td>\n",
       "      <td>1.0675</td>\n",
       "      <td>1.2464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.180323</td>\n",
       "      <td>217.615258</td>\n",
       "      <td>15143.431641</td>\n",
       "      <td>1.0635</td>\n",
       "      <td>1.2577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.181613</td>\n",
       "      <td>217.656290</td>\n",
       "      <td>15150.730207</td>\n",
       "      <td>1.0587</td>\n",
       "      <td>1.2646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.181935</td>\n",
       "      <td>217.666548</td>\n",
       "      <td>15152.554848</td>\n",
       "      <td>1.0545</td>\n",
       "      <td>1.2594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.182258</td>\n",
       "      <td>217.676806</td>\n",
       "      <td>15154.379489</td>\n",
       "      <td>1.0502</td>\n",
       "      <td>1.2683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.182581</td>\n",
       "      <td>217.687065</td>\n",
       "      <td>15156.204130</td>\n",
       "      <td>1.0577</td>\n",
       "      <td>1.2639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.183548</td>\n",
       "      <td>217.717839</td>\n",
       "      <td>15161.678054</td>\n",
       "      <td>1.0621</td>\n",
       "      <td>1.2573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.183871</td>\n",
       "      <td>217.728097</td>\n",
       "      <td>15163.502696</td>\n",
       "      <td>1.0524</td>\n",
       "      <td>1.2719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.184194</td>\n",
       "      <td>217.738355</td>\n",
       "      <td>15165.327337</td>\n",
       "      <td>1.0556</td>\n",
       "      <td>1.2755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.184516</td>\n",
       "      <td>217.748613</td>\n",
       "      <td>15167.151978</td>\n",
       "      <td>1.0421</td>\n",
       "      <td>1.2893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.184839</td>\n",
       "      <td>217.758871</td>\n",
       "      <td>15168.976620</td>\n",
       "      <td>1.0522</td>\n",
       "      <td>1.2919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.185806</td>\n",
       "      <td>217.789645</td>\n",
       "      <td>15174.450543</td>\n",
       "      <td>1.0524</td>\n",
       "      <td>1.2963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.186129</td>\n",
       "      <td>217.799903</td>\n",
       "      <td>15176.275185</td>\n",
       "      <td>1.0481</td>\n",
       "      <td>1.2905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.186452</td>\n",
       "      <td>217.810161</td>\n",
       "      <td>15178.099826</td>\n",
       "      <td>1.0520</td>\n",
       "      <td>1.2818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.186774</td>\n",
       "      <td>217.820419</td>\n",
       "      <td>15179.924467</td>\n",
       "      <td>1.0403</td>\n",
       "      <td>1.2903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.187097</td>\n",
       "      <td>217.830677</td>\n",
       "      <td>15181.749109</td>\n",
       "      <td>1.0529</td>\n",
       "      <td>1.2874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.188065</td>\n",
       "      <td>217.861452</td>\n",
       "      <td>15187.223033</td>\n",
       "      <td>1.0480</td>\n",
       "      <td>1.2983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.188387</td>\n",
       "      <td>217.871710</td>\n",
       "      <td>15189.047674</td>\n",
       "      <td>1.0622</td>\n",
       "      <td>1.2983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.188710</td>\n",
       "      <td>217.881968</td>\n",
       "      <td>15190.872315</td>\n",
       "      <td>1.0578</td>\n",
       "      <td>1.2998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.189032</td>\n",
       "      <td>217.892226</td>\n",
       "      <td>15192.696957</td>\n",
       "      <td>1.0412</td>\n",
       "      <td>1.3064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.189355</td>\n",
       "      <td>217.902484</td>\n",
       "      <td>15194.521598</td>\n",
       "      <td>1.0410</td>\n",
       "      <td>1.3069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.190000</td>\n",
       "      <td>217.934355</td>\n",
       "      <td>15199.995522</td>\n",
       "      <td>1.0379</td>\n",
       "      <td>1.3174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.190000</td>\n",
       "      <td>217.945710</td>\n",
       "      <td>15201.820163</td>\n",
       "      <td>1.0384</td>\n",
       "      <td>1.3239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.190000</td>\n",
       "      <td>217.957065</td>\n",
       "      <td>15203.644804</td>\n",
       "      <td>1.0514</td>\n",
       "      <td>1.3158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.190000</td>\n",
       "      <td>217.968419</td>\n",
       "      <td>15205.469446</td>\n",
       "      <td>1.0475</td>\n",
       "      <td>1.3157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.190000</td>\n",
       "      <td>217.979774</td>\n",
       "      <td>15207.294087</td>\n",
       "      <td>1.0365</td>\n",
       "      <td>1.3282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.190000</td>\n",
       "      <td>218.013839</td>\n",
       "      <td>15212.768011</td>\n",
       "      <td>1.0457</td>\n",
       "      <td>1.3241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.190000</td>\n",
       "      <td>218.025194</td>\n",
       "      <td>15214.592652</td>\n",
       "      <td>1.0575</td>\n",
       "      <td>1.3095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     us_rates_%         CPI           GDP  usd_chf  eur_usd\n",
       "100    0.180000  217.212533  15090.167374   1.1575   1.2206\n",
       "101    0.180000  217.226067  15091.941154   1.1540   1.2193\n",
       "102    0.180000  217.239600  15093.714934   1.1614   1.1998\n",
       "103    0.180000  217.280200  15099.036275   1.1613   1.1959\n",
       "104    0.180000  217.293733  15100.810055   1.1510   1.1995\n",
       "105    0.180000  217.307267  15102.583835   1.1455   1.2045\n",
       "106    0.180000  217.320800  15104.357615   1.1418   1.2111\n",
       "107    0.180000  217.334333  15106.131396   1.1521   1.2077\n",
       "108    0.180000  217.374933  15111.452736   1.1378   1.2277\n",
       "109    0.180000  217.388467  15113.226516   1.1310   1.2327\n",
       "110    0.180000  217.402000  15115.000297   1.1267   1.2323\n",
       "111    0.180000  217.415533  15116.774077   1.1137   1.2365\n",
       "112    0.180000  217.429067  15118.547857   1.1107   1.2360\n",
       "113    0.180000  217.469667  15123.869198   1.1080   1.2385\n",
       "114    0.180000  217.483200  15125.642978   1.1047   1.2303\n",
       "115    0.180000  217.496733  15127.416758   1.1053   1.2310\n",
       "116    0.180000  217.510267  15129.190538   1.1048   1.2288\n",
       "117    0.180000  217.523800  15130.964319   1.0937   1.2332\n",
       "118    0.180000  217.564400  15136.285659   1.0860   1.2316\n",
       "119    0.180000  217.577933  15138.059440   1.0810   1.2187\n",
       "120    0.180000  217.591467  15139.833220   1.0774   1.2291\n",
       "121    0.180000  217.605000  15141.607000   1.0675   1.2464\n",
       "122    0.180323  217.615258  15143.431641   1.0635   1.2577\n",
       "124    0.181613  217.656290  15150.730207   1.0587   1.2646\n",
       "125    0.181935  217.666548  15152.554848   1.0545   1.2594\n",
       "126    0.182258  217.676806  15154.379489   1.0502   1.2683\n",
       "127    0.182581  217.687065  15156.204130   1.0577   1.2639\n",
       "128    0.183548  217.717839  15161.678054   1.0621   1.2573\n",
       "129    0.183871  217.728097  15163.502696   1.0524   1.2719\n",
       "130    0.184194  217.738355  15165.327337   1.0556   1.2755\n",
       "131    0.184516  217.748613  15167.151978   1.0421   1.2893\n",
       "132    0.184839  217.758871  15168.976620   1.0522   1.2919\n",
       "133    0.185806  217.789645  15174.450543   1.0524   1.2963\n",
       "134    0.186129  217.799903  15176.275185   1.0481   1.2905\n",
       "135    0.186452  217.810161  15178.099826   1.0520   1.2818\n",
       "136    0.186774  217.820419  15179.924467   1.0403   1.2903\n",
       "137    0.187097  217.830677  15181.749109   1.0529   1.2874\n",
       "138    0.188065  217.861452  15187.223033   1.0480   1.2983\n",
       "139    0.188387  217.871710  15189.047674   1.0622   1.2983\n",
       "140    0.188710  217.881968  15190.872315   1.0578   1.2998\n",
       "141    0.189032  217.892226  15192.696957   1.0412   1.3064\n",
       "142    0.189355  217.902484  15194.521598   1.0410   1.3069\n",
       "144    0.190000  217.934355  15199.995522   1.0379   1.3174\n",
       "145    0.190000  217.945710  15201.820163   1.0384   1.3239\n",
       "146    0.190000  217.957065  15203.644804   1.0514   1.3158\n",
       "147    0.190000  217.968419  15205.469446   1.0475   1.3157\n",
       "148    0.190000  217.979774  15207.294087   1.0365   1.3282\n",
       "149    0.190000  218.013839  15212.768011   1.0457   1.3241\n",
       "150    0.190000  218.025194  15214.592652   1.0575   1.3095"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[100:150,('us_rates_%','CPI','GDP','usd_chf','eur_usd')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sp500 open</th>\n",
       "      <th>sp500 high</th>\n",
       "      <th>sp500 low</th>\n",
       "      <th>sp500 close</th>\n",
       "      <th>sp500 volume</th>\n",
       "      <th>sp500 high-low</th>\n",
       "      <th>nasdaq open</th>\n",
       "      <th>nasdaq high</th>\n",
       "      <th>nasdaq low</th>\n",
       "      <th>...</th>\n",
       "      <th>palladium high</th>\n",
       "      <th>palladium low</th>\n",
       "      <th>palladium close</th>\n",
       "      <th>palladium volume</th>\n",
       "      <th>palladium high-low</th>\n",
       "      <th>gold open</th>\n",
       "      <th>gold high</th>\n",
       "      <th>gold low</th>\n",
       "      <th>gold close</th>\n",
       "      <th>gold volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-14</td>\n",
       "      <td>114.49</td>\n",
       "      <td>115.14</td>\n",
       "      <td>114.42</td>\n",
       "      <td>114.93</td>\n",
       "      <td>115646960.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>46.26</td>\n",
       "      <td>46.520</td>\n",
       "      <td>46.22</td>\n",
       "      <td>...</td>\n",
       "      <td>45.02</td>\n",
       "      <td>43.86</td>\n",
       "      <td>44.84</td>\n",
       "      <td>364528.0</td>\n",
       "      <td>1.16</td>\n",
       "      <td>111.51</td>\n",
       "      <td>112.37</td>\n",
       "      <td>110.79</td>\n",
       "      <td>112.03</td>\n",
       "      <td>18305238.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-15</td>\n",
       "      <td>114.73</td>\n",
       "      <td>114.84</td>\n",
       "      <td>113.20</td>\n",
       "      <td>113.64</td>\n",
       "      <td>212252769.0</td>\n",
       "      <td>1.64</td>\n",
       "      <td>46.46</td>\n",
       "      <td>46.550</td>\n",
       "      <td>45.65</td>\n",
       "      <td>...</td>\n",
       "      <td>45.76</td>\n",
       "      <td>44.40</td>\n",
       "      <td>45.76</td>\n",
       "      <td>442210.0</td>\n",
       "      <td>1.36</td>\n",
       "      <td>111.35</td>\n",
       "      <td>112.01</td>\n",
       "      <td>110.38</td>\n",
       "      <td>110.86</td>\n",
       "      <td>18000724.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-19</td>\n",
       "      <td>113.62</td>\n",
       "      <td>115.13</td>\n",
       "      <td>113.59</td>\n",
       "      <td>115.06</td>\n",
       "      <td>138671890.0</td>\n",
       "      <td>1.54</td>\n",
       "      <td>45.96</td>\n",
       "      <td>46.640</td>\n",
       "      <td>45.95</td>\n",
       "      <td>...</td>\n",
       "      <td>47.08</td>\n",
       "      <td>45.70</td>\n",
       "      <td>46.94</td>\n",
       "      <td>629150.0</td>\n",
       "      <td>1.38</td>\n",
       "      <td>110.95</td>\n",
       "      <td>111.75</td>\n",
       "      <td>110.83</td>\n",
       "      <td>111.52</td>\n",
       "      <td>10467927.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-20</td>\n",
       "      <td>114.28</td>\n",
       "      <td>114.45</td>\n",
       "      <td>112.98</td>\n",
       "      <td>113.89</td>\n",
       "      <td>216330645.0</td>\n",
       "      <td>1.47</td>\n",
       "      <td>46.27</td>\n",
       "      <td>46.604</td>\n",
       "      <td>45.43</td>\n",
       "      <td>...</td>\n",
       "      <td>47.31</td>\n",
       "      <td>45.17</td>\n",
       "      <td>47.05</td>\n",
       "      <td>643198.0</td>\n",
       "      <td>2.14</td>\n",
       "      <td>109.97</td>\n",
       "      <td>110.05</td>\n",
       "      <td>108.46</td>\n",
       "      <td>108.94</td>\n",
       "      <td>17534231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2010-01-21</td>\n",
       "      <td>113.92</td>\n",
       "      <td>114.27</td>\n",
       "      <td>111.56</td>\n",
       "      <td>111.70</td>\n",
       "      <td>344747028.0</td>\n",
       "      <td>2.71</td>\n",
       "      <td>46.06</td>\n",
       "      <td>46.350</td>\n",
       "      <td>45.30</td>\n",
       "      <td>...</td>\n",
       "      <td>46.98</td>\n",
       "      <td>45.07</td>\n",
       "      <td>45.30</td>\n",
       "      <td>388457.0</td>\n",
       "      <td>1.91</td>\n",
       "      <td>108.48</td>\n",
       "      <td>108.78</td>\n",
       "      <td>106.61</td>\n",
       "      <td>107.37</td>\n",
       "      <td>25747831.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  sp500 open  sp500 high  sp500 low  sp500 close  sp500 volume  \\\n",
       "0 2010-01-14      114.49      115.14     114.42       114.93   115646960.0   \n",
       "1 2010-01-15      114.73      114.84     113.20       113.64   212252769.0   \n",
       "3 2010-01-19      113.62      115.13     113.59       115.06   138671890.0   \n",
       "4 2010-01-20      114.28      114.45     112.98       113.89   216330645.0   \n",
       "5 2010-01-21      113.92      114.27     111.56       111.70   344747028.0   \n",
       "\n",
       "   sp500 high-low  nasdaq open  nasdaq high  nasdaq low  ...  palladium high  \\\n",
       "0            0.72        46.26       46.520       46.22  ...           45.02   \n",
       "1            1.64        46.46       46.550       45.65  ...           45.76   \n",
       "3            1.54        45.96       46.640       45.95  ...           47.08   \n",
       "4            1.47        46.27       46.604       45.43  ...           47.31   \n",
       "5            2.71        46.06       46.350       45.30  ...           46.98   \n",
       "\n",
       "   palladium low  palladium close  palladium volume  palladium high-low  \\\n",
       "0          43.86            44.84          364528.0                1.16   \n",
       "1          44.40            45.76          442210.0                1.36   \n",
       "3          45.70            46.94          629150.0                1.38   \n",
       "4          45.17            47.05          643198.0                2.14   \n",
       "5          45.07            45.30          388457.0                1.91   \n",
       "\n",
       "   gold open  gold high  gold low  gold close  gold volume  \n",
       "0     111.51     112.37    110.79      112.03   18305238.0  \n",
       "1     111.35     112.01    110.38      110.86   18000724.0  \n",
       "3     110.95     111.75    110.83      111.52   10467927.0  \n",
       "4     109.97     110.05    108.46      108.94   17534231.0  \n",
       "5     108.48     108.78    106.61      107.37   25747831.0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create numeric features from date\n",
    "df['days_since_start'] = (df['date'] - df['date'].min()).dt.days\n",
    "df['month'] = df['date'].dt.month\n",
    "df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "\n",
    "# Drop raw date column\n",
    "df = df.drop(columns=['date','month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sp500 open</th>\n",
       "      <th>sp500 high</th>\n",
       "      <th>sp500 low</th>\n",
       "      <th>sp500 close</th>\n",
       "      <th>sp500 volume</th>\n",
       "      <th>sp500 high-low</th>\n",
       "      <th>nasdaq open</th>\n",
       "      <th>nasdaq high</th>\n",
       "      <th>nasdaq low</th>\n",
       "      <th>nasdaq close</th>\n",
       "      <th>...</th>\n",
       "      <th>palladium high-low</th>\n",
       "      <th>gold open</th>\n",
       "      <th>gold high</th>\n",
       "      <th>gold low</th>\n",
       "      <th>gold close</th>\n",
       "      <th>gold volume</th>\n",
       "      <th>days_since_start</th>\n",
       "      <th>month</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114.49</td>\n",
       "      <td>115.14</td>\n",
       "      <td>114.42</td>\n",
       "      <td>114.93</td>\n",
       "      <td>115646960.0</td>\n",
       "      <td>0.72</td>\n",
       "      <td>46.26</td>\n",
       "      <td>46.520</td>\n",
       "      <td>46.22</td>\n",
       "      <td>46.39</td>\n",
       "      <td>...</td>\n",
       "      <td>1.16</td>\n",
       "      <td>111.51</td>\n",
       "      <td>112.37</td>\n",
       "      <td>110.79</td>\n",
       "      <td>112.03</td>\n",
       "      <td>18305238.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114.73</td>\n",
       "      <td>114.84</td>\n",
       "      <td>113.20</td>\n",
       "      <td>113.64</td>\n",
       "      <td>212252769.0</td>\n",
       "      <td>1.64</td>\n",
       "      <td>46.46</td>\n",
       "      <td>46.550</td>\n",
       "      <td>45.65</td>\n",
       "      <td>45.85</td>\n",
       "      <td>...</td>\n",
       "      <td>1.36</td>\n",
       "      <td>111.35</td>\n",
       "      <td>112.01</td>\n",
       "      <td>110.38</td>\n",
       "      <td>110.86</td>\n",
       "      <td>18000724.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>113.62</td>\n",
       "      <td>115.13</td>\n",
       "      <td>113.59</td>\n",
       "      <td>115.06</td>\n",
       "      <td>138671890.0</td>\n",
       "      <td>1.54</td>\n",
       "      <td>45.96</td>\n",
       "      <td>46.640</td>\n",
       "      <td>45.95</td>\n",
       "      <td>46.59</td>\n",
       "      <td>...</td>\n",
       "      <td>1.38</td>\n",
       "      <td>110.95</td>\n",
       "      <td>111.75</td>\n",
       "      <td>110.83</td>\n",
       "      <td>111.52</td>\n",
       "      <td>10467927.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>114.28</td>\n",
       "      <td>114.45</td>\n",
       "      <td>112.98</td>\n",
       "      <td>113.89</td>\n",
       "      <td>216330645.0</td>\n",
       "      <td>1.47</td>\n",
       "      <td>46.27</td>\n",
       "      <td>46.604</td>\n",
       "      <td>45.43</td>\n",
       "      <td>45.92</td>\n",
       "      <td>...</td>\n",
       "      <td>2.14</td>\n",
       "      <td>109.97</td>\n",
       "      <td>110.05</td>\n",
       "      <td>108.46</td>\n",
       "      <td>108.94</td>\n",
       "      <td>17534231.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>113.92</td>\n",
       "      <td>114.27</td>\n",
       "      <td>111.56</td>\n",
       "      <td>111.70</td>\n",
       "      <td>344747028.0</td>\n",
       "      <td>2.71</td>\n",
       "      <td>46.06</td>\n",
       "      <td>46.350</td>\n",
       "      <td>45.30</td>\n",
       "      <td>45.49</td>\n",
       "      <td>...</td>\n",
       "      <td>1.91</td>\n",
       "      <td>108.48</td>\n",
       "      <td>108.78</td>\n",
       "      <td>106.61</td>\n",
       "      <td>107.37</td>\n",
       "      <td>25747831.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sp500 open  sp500 high  sp500 low  sp500 close  sp500 volume  \\\n",
       "0      114.49      115.14     114.42       114.93   115646960.0   \n",
       "1      114.73      114.84     113.20       113.64   212252769.0   \n",
       "3      113.62      115.13     113.59       115.06   138671890.0   \n",
       "4      114.28      114.45     112.98       113.89   216330645.0   \n",
       "5      113.92      114.27     111.56       111.70   344747028.0   \n",
       "\n",
       "   sp500 high-low  nasdaq open  nasdaq high  nasdaq low  nasdaq close  ...  \\\n",
       "0            0.72        46.26       46.520       46.22         46.39  ...   \n",
       "1            1.64        46.46       46.550       45.65         45.85  ...   \n",
       "3            1.54        45.96       46.640       45.95         46.59  ...   \n",
       "4            1.47        46.27       46.604       45.43         45.92  ...   \n",
       "5            2.71        46.06       46.350       45.30         45.49  ...   \n",
       "\n",
       "   palladium high-low  gold open  gold high  gold low  gold close  \\\n",
       "0                1.16     111.51     112.37    110.79      112.03   \n",
       "1                1.36     111.35     112.01    110.38      110.86   \n",
       "3                1.38     110.95     111.75    110.83      111.52   \n",
       "4                2.14     109.97     110.05    108.46      108.94   \n",
       "5                1.91     108.48     108.78    106.61      107.37   \n",
       "\n",
       "   gold volume  days_since_start  month  month_sin  month_cos  \n",
       "0   18305238.0                 0      1        0.5   0.866025  \n",
       "1   18000724.0                 1      1        0.5   0.866025  \n",
       "3   10467927.0                 5      1        0.5   0.866025  \n",
       "4   17534231.0                 6      1        0.5   0.866025  \n",
       "5   25747831.0                 7      1        0.5   0.866025  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nulls = df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "import os\n",
    "project_root = os.path.abspath(\"..\")  # Add the project root to the Python path\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "    sys.path.append(os.path.abspath('../src/'))\n",
    "\n",
    "from src.data_preprocessing import DataPreprocessor \n",
    "from src.feature_engineering import FeatureEngineering\n",
    "from src.lstm import lstm\n",
    "from src.feature_selection import FeatureSelectionWithRFE\n",
    "from src.evaluate import ModelEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test the preprocessing\n",
    "file_path = (\n",
    "    \"./data/raw/financial_regression.csv\"  # Adjust the path based on your directory structure\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been loaded\n",
      "No null values found\n",
      "Data is saved\n"
     ]
    }
   ],
   "source": [
    "# Creating an instance of the DataPreprocessor class\n",
    "dp = DataPreprocessor(file_path=file_path)\n",
    "\n",
    "# Calling the preprocess method which which will perform all the preprocessing steps\n",
    "df_preprocess = dp.preprocess()\n",
    "\n",
    "# Creating an instance of the feature engineering class\n",
    "ft = FeatureEngineering(df=df_preprocess, dependent_variable='gold close')\n",
    "\n",
    "df_transformed = ft.data_transformation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sp500 open</th>\n",
       "      <th>sp500 high</th>\n",
       "      <th>sp500 low</th>\n",
       "      <th>sp500 close</th>\n",
       "      <th>sp500 volume</th>\n",
       "      <th>sp500 high-low</th>\n",
       "      <th>nasdaq open</th>\n",
       "      <th>nasdaq high</th>\n",
       "      <th>nasdaq low</th>\n",
       "      <th>nasdaq close</th>\n",
       "      <th>...</th>\n",
       "      <th>palladium high</th>\n",
       "      <th>palladium low</th>\n",
       "      <th>palladium close</th>\n",
       "      <th>palladium volume</th>\n",
       "      <th>palladium high-low</th>\n",
       "      <th>gold volume</th>\n",
       "      <th>days_since_start</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>gold close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.270967</td>\n",
       "      <td>-1.270730</td>\n",
       "      <td>-1.265986</td>\n",
       "      <td>-1.267529</td>\n",
       "      <td>0.046746</td>\n",
       "      <td>-0.866654</td>\n",
       "      <td>-1.103567</td>\n",
       "      <td>-1.103690</td>\n",
       "      <td>-1.101662</td>\n",
       "      <td>-1.102769</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.114946</td>\n",
       "      <td>-1.126631</td>\n",
       "      <td>-1.113514</td>\n",
       "      <td>2.991326</td>\n",
       "      <td>-0.429607</td>\n",
       "      <td>1.398865</td>\n",
       "      <td>-1.731300</td>\n",
       "      <td>0.712098</td>\n",
       "      <td>1.264762</td>\n",
       "      <td>112.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.268989</td>\n",
       "      <td>-1.273189</td>\n",
       "      <td>-1.276099</td>\n",
       "      <td>-1.278157</td>\n",
       "      <td>1.446430</td>\n",
       "      <td>-0.520342</td>\n",
       "      <td>-1.101933</td>\n",
       "      <td>-1.103447</td>\n",
       "      <td>-1.106356</td>\n",
       "      <td>-1.107179</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.102285</td>\n",
       "      <td>-1.117136</td>\n",
       "      <td>-1.097564</td>\n",
       "      <td>3.784859</td>\n",
       "      <td>-0.350968</td>\n",
       "      <td>1.349603</td>\n",
       "      <td>-1.730658</td>\n",
       "      <td>0.712098</td>\n",
       "      <td>1.264762</td>\n",
       "      <td>110.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.278136</td>\n",
       "      <td>-1.270812</td>\n",
       "      <td>-1.272866</td>\n",
       "      <td>-1.266458</td>\n",
       "      <td>0.380345</td>\n",
       "      <td>-0.557985</td>\n",
       "      <td>-1.106017</td>\n",
       "      <td>-1.102718</td>\n",
       "      <td>-1.103885</td>\n",
       "      <td>-1.101136</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.079700</td>\n",
       "      <td>-1.094277</td>\n",
       "      <td>-1.077107</td>\n",
       "      <td>5.694478</td>\n",
       "      <td>-0.343105</td>\n",
       "      <td>0.131002</td>\n",
       "      <td>-1.728091</td>\n",
       "      <td>0.712098</td>\n",
       "      <td>1.264762</td>\n",
       "      <td>111.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.272697</td>\n",
       "      <td>-1.276385</td>\n",
       "      <td>-1.277922</td>\n",
       "      <td>-1.276098</td>\n",
       "      <td>1.505513</td>\n",
       "      <td>-0.584334</td>\n",
       "      <td>-1.103485</td>\n",
       "      <td>-1.103009</td>\n",
       "      <td>-1.108168</td>\n",
       "      <td>-1.106607</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.075765</td>\n",
       "      <td>-1.103596</td>\n",
       "      <td>-1.075200</td>\n",
       "      <td>5.837980</td>\n",
       "      <td>-0.044278</td>\n",
       "      <td>1.274137</td>\n",
       "      <td>-1.727449</td>\n",
       "      <td>0.712098</td>\n",
       "      <td>1.264762</td>\n",
       "      <td>108.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1.275664</td>\n",
       "      <td>-1.277860</td>\n",
       "      <td>-1.289692</td>\n",
       "      <td>-1.294140</td>\n",
       "      <td>3.366088</td>\n",
       "      <td>-0.117565</td>\n",
       "      <td>-1.105200</td>\n",
       "      <td>-1.105068</td>\n",
       "      <td>-1.109239</td>\n",
       "      <td>-1.110118</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.081411</td>\n",
       "      <td>-1.105354</td>\n",
       "      <td>-1.105539</td>\n",
       "      <td>3.235764</td>\n",
       "      <td>-0.134712</td>\n",
       "      <td>2.602874</td>\n",
       "      <td>-1.726807</td>\n",
       "      <td>0.712098</td>\n",
       "      <td>1.264762</td>\n",
       "      <td>107.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3899</th>\n",
       "      <td>2.613555</td>\n",
       "      <td>2.589495</td>\n",
       "      <td>2.610944</td>\n",
       "      <td>2.583436</td>\n",
       "      <td>-1.130501</td>\n",
       "      <td>0.352968</td>\n",
       "      <td>2.572798</td>\n",
       "      <td>2.543429</td>\n",
       "      <td>2.563092</td>\n",
       "      <td>2.530016</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.242249</td>\n",
       "      <td>-0.235481</td>\n",
       "      <td>-0.232106</td>\n",
       "      <td>-0.196964</td>\n",
       "      <td>-0.301465</td>\n",
       "      <td>-0.725060</td>\n",
       "      <td>1.727960</td>\n",
       "      <td>-1.209013</td>\n",
       "      <td>0.743903</td>\n",
       "      <td>248.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3900</th>\n",
       "      <td>2.598393</td>\n",
       "      <td>2.583511</td>\n",
       "      <td>2.614426</td>\n",
       "      <td>2.601891</td>\n",
       "      <td>-1.086700</td>\n",
       "      <td>-0.079923</td>\n",
       "      <td>2.553361</td>\n",
       "      <td>2.535973</td>\n",
       "      <td>2.580469</td>\n",
       "      <td>2.556311</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.180071</td>\n",
       "      <td>-0.187477</td>\n",
       "      <td>-0.166573</td>\n",
       "      <td>1.362000</td>\n",
       "      <td>0.054020</td>\n",
       "      <td>-0.295158</td>\n",
       "      <td>1.728602</td>\n",
       "      <td>-1.209013</td>\n",
       "      <td>0.743903</td>\n",
       "      <td>251.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3901</th>\n",
       "      <td>2.596580</td>\n",
       "      <td>2.579086</td>\n",
       "      <td>2.598015</td>\n",
       "      <td>2.593982</td>\n",
       "      <td>-1.100867</td>\n",
       "      <td>0.462094</td>\n",
       "      <td>2.546747</td>\n",
       "      <td>2.541322</td>\n",
       "      <td>2.564079</td>\n",
       "      <td>2.564069</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.202485</td>\n",
       "      <td>-0.211742</td>\n",
       "      <td>-0.203154</td>\n",
       "      <td>1.590482</td>\n",
       "      <td>0.081544</td>\n",
       "      <td>-0.064636</td>\n",
       "      <td>1.730527</td>\n",
       "      <td>-1.209013</td>\n",
       "      <td>0.743903</td>\n",
       "      <td>251.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3902</th>\n",
       "      <td>2.573508</td>\n",
       "      <td>2.576217</td>\n",
       "      <td>2.596191</td>\n",
       "      <td>2.591428</td>\n",
       "      <td>-1.133542</td>\n",
       "      <td>0.413196</td>\n",
       "      <td>2.542500</td>\n",
       "      <td>2.551170</td>\n",
       "      <td>2.569515</td>\n",
       "      <td>2.568478</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.181270</td>\n",
       "      <td>-0.175344</td>\n",
       "      <td>-0.167440</td>\n",
       "      <td>0.661282</td>\n",
       "      <td>-0.244846</td>\n",
       "      <td>-0.631208</td>\n",
       "      <td>1.731169</td>\n",
       "      <td>-1.209013</td>\n",
       "      <td>0.743903</td>\n",
       "      <td>253.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3903</th>\n",
       "      <td>2.575239</td>\n",
       "      <td>2.553338</td>\n",
       "      <td>2.546749</td>\n",
       "      <td>2.547515</td>\n",
       "      <td>-0.941406</td>\n",
       "      <td>1.607824</td>\n",
       "      <td>2.549523</td>\n",
       "      <td>2.525274</td>\n",
       "      <td>2.512522</td>\n",
       "      <td>2.506416</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.199063</td>\n",
       "      <td>-0.201644</td>\n",
       "      <td>-0.200033</td>\n",
       "      <td>0.096405</td>\n",
       "      <td>-0.065628</td>\n",
       "      <td>-0.284420</td>\n",
       "      <td>1.731811</td>\n",
       "      <td>-1.209013</td>\n",
       "      <td>0.743903</td>\n",
       "      <td>250.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3719 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sp500 open  sp500 high  sp500 low  sp500 close  sp500 volume  \\\n",
       "0      -1.270967   -1.270730  -1.265986    -1.267529      0.046746   \n",
       "1      -1.268989   -1.273189  -1.276099    -1.278157      1.446430   \n",
       "3      -1.278136   -1.270812  -1.272866    -1.266458      0.380345   \n",
       "4      -1.272697   -1.276385  -1.277922    -1.276098      1.505513   \n",
       "5      -1.275664   -1.277860  -1.289692    -1.294140      3.366088   \n",
       "...          ...         ...        ...          ...           ...   \n",
       "3899    2.613555    2.589495   2.610944     2.583436     -1.130501   \n",
       "3900    2.598393    2.583511   2.614426     2.601891     -1.086700   \n",
       "3901    2.596580    2.579086   2.598015     2.593982     -1.100867   \n",
       "3902    2.573508    2.576217   2.596191     2.591428     -1.133542   \n",
       "3903    2.575239    2.553338   2.546749     2.547515     -0.941406   \n",
       "\n",
       "      sp500 high-low  nasdaq open  nasdaq high  nasdaq low  nasdaq close  ...  \\\n",
       "0          -0.866654    -1.103567    -1.103690   -1.101662     -1.102769  ...   \n",
       "1          -0.520342    -1.101933    -1.103447   -1.106356     -1.107179  ...   \n",
       "3          -0.557985    -1.106017    -1.102718   -1.103885     -1.101136  ...   \n",
       "4          -0.584334    -1.103485    -1.103009   -1.108168     -1.106607  ...   \n",
       "5          -0.117565    -1.105200    -1.105068   -1.109239     -1.110118  ...   \n",
       "...              ...          ...          ...         ...           ...  ...   \n",
       "3899        0.352968     2.572798     2.543429    2.563092      2.530016  ...   \n",
       "3900       -0.079923     2.553361     2.535973    2.580469      2.556311  ...   \n",
       "3901        0.462094     2.546747     2.541322    2.564079      2.564069  ...   \n",
       "3902        0.413196     2.542500     2.551170    2.569515      2.568478  ...   \n",
       "3903        1.607824     2.549523     2.525274    2.512522      2.506416  ...   \n",
       "\n",
       "      palladium high  palladium low  palladium close  palladium volume  \\\n",
       "0          -1.114946      -1.126631        -1.113514          2.991326   \n",
       "1          -1.102285      -1.117136        -1.097564          3.784859   \n",
       "3          -1.079700      -1.094277        -1.077107          5.694478   \n",
       "4          -1.075765      -1.103596        -1.075200          5.837980   \n",
       "5          -1.081411      -1.105354        -1.105539          3.235764   \n",
       "...              ...            ...              ...               ...   \n",
       "3899       -0.242249      -0.235481        -0.232106         -0.196964   \n",
       "3900       -0.180071      -0.187477        -0.166573          1.362000   \n",
       "3901       -0.202485      -0.211742        -0.203154          1.590482   \n",
       "3902       -0.181270      -0.175344        -0.167440          0.661282   \n",
       "3903       -0.199063      -0.201644        -0.200033          0.096405   \n",
       "\n",
       "      palladium high-low  gold volume  days_since_start  month_sin  month_cos  \\\n",
       "0              -0.429607     1.398865         -1.731300   0.712098   1.264762   \n",
       "1              -0.350968     1.349603         -1.730658   0.712098   1.264762   \n",
       "3              -0.343105     0.131002         -1.728091   0.712098   1.264762   \n",
       "4              -0.044278     1.274137         -1.727449   0.712098   1.264762   \n",
       "5              -0.134712     2.602874         -1.726807   0.712098   1.264762   \n",
       "...                  ...          ...               ...        ...        ...   \n",
       "3899           -0.301465    -0.725060          1.727960  -1.209013   0.743903   \n",
       "3900            0.054020    -0.295158          1.728602  -1.209013   0.743903   \n",
       "3901            0.081544    -0.064636          1.730527  -1.209013   0.743903   \n",
       "3902           -0.244846    -0.631208          1.731169  -1.209013   0.743903   \n",
       "3903           -0.065628    -0.284420          1.731811  -1.209013   0.743903   \n",
       "\n",
       "      gold close  \n",
       "0         112.03  \n",
       "1         110.86  \n",
       "3         111.52  \n",
       "4         108.94  \n",
       "5         107.37  \n",
       "...          ...  \n",
       "3899      248.63  \n",
       "3900      251.27  \n",
       "3901      251.22  \n",
       "3902      253.93  \n",
       "3903      250.87  \n",
       "\n",
       "[3719 rows x 46 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a%pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from lightgbm import LGBMRegressor\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, GRU, Bidirectional, Activation, Flatten, LSTM, TimeDistributed, RepeatVector\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'data' is your preprocessed pandas dataframe\n",
    "\n",
    "# Separate the target and features\n",
    "X = df_transformed.drop(columns=['gold close'])\n",
    "y = df_transformed['gold close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train, validation, and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = FeatureSelectionWithRFE(X_train, y_train, X_test,y_test, n_features_to_select=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003434 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10986\n",
      "[LightGBM] [Info] Number of data points in the train set: 2603, number of used features: 45\n",
      "[LightGBM] [Info] Start training from score 130.398183\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000869 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10731\n",
      "[LightGBM] [Info] Number of data points in the train set: 2603, number of used features: 44\n",
      "[LightGBM] [Info] Start training from score 130.398183\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001581 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10476\n",
      "[LightGBM] [Info] Number of data points in the train set: 2603, number of used features: 43\n",
      "[LightGBM] [Info] Start training from score 130.398183\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000634 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10221\n",
      "[LightGBM] [Info] Number of data points in the train set: 2603, number of used features: 42\n",
      "[LightGBM] [Info] Start training from score 130.398183\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001509 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9966\n",
      "[LightGBM] [Info] Number of data points in the train set: 2603, number of used features: 41\n",
      "[LightGBM] [Info] Start training from score 130.398183\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9711\n",
      "[LightGBM] [Info] Number of data points in the train set: 2603, number of used features: 40\n",
      "[LightGBM] [Info] Start training from score 130.398183\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000744 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9456\n",
      "[LightGBM] [Info] Number of data points in the train set: 2603, number of used features: 39\n",
      "[LightGBM] [Info] Start training from score 130.398183\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000847 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9201\n",
      "[LightGBM] [Info] Number of data points in the train set: 2603, number of used features: 38\n",
      "[LightGBM] [Info] Start training from score 130.398183\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000318 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 8946\n",
      "[LightGBM] [Info] Number of data points in the train set: 2603, number of used features: 37\n",
      "[LightGBM] [Info] Start training from score 130.398183\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000863 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8691\n",
      "[LightGBM] [Info] Number of data points in the train set: 2603, number of used features: 36\n",
      "[LightGBM] [Info] Start training from score 130.398183\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000726 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8436\n",
      "[LightGBM] [Info] Number of data points in the train set: 2603, number of used features: 35\n",
      "[LightGBM] [Info] Start training from score 130.398183\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8181\n",
      "[LightGBM] [Info] Number of data points in the train set: 2603, number of used features: 34\n",
      "[LightGBM] [Info] Start training from score 130.398183\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7926\n",
      "[LightGBM] [Info] Number of data points in the train set: 2603, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score 130.398183\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001097 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7671\n",
      "[LightGBM] [Info] Number of data points in the train set: 2603, number of used features: 32\n",
      "[LightGBM] [Info] Start training from score 130.398183\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7416\n",
      "[LightGBM] [Info] Number of data points in the train set: 2603, number of used features: 31\n",
      "[LightGBM] [Info] Start training from score 130.398183\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 7161\n",
      "[LightGBM] [Info] Number of data points in the train set: 2603, number of used features: 30\n",
      "[LightGBM] [Info] Start training from score 130.398183\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000717 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6906\n",
      "[LightGBM] [Info] Number of data points in the train set: 2603, number of used features: 29\n",
      "[LightGBM] [Info] Start training from score 130.398183\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000512 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6651\n",
      "[LightGBM] [Info] Number of data points in the train set: 2603, number of used features: 28\n",
      "[LightGBM] [Info] Start training from score 130.398183\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000938 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6396\n",
      "[LightGBM] [Info] Number of data points in the train set: 2603, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score 130.398183\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001646 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 6141\n",
      "[LightGBM] [Info] Number of data points in the train set: 2603, number of used features: 26\n",
      "[LightGBM] [Info] Start training from score 130.398183\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000681 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5886\n",
      "[LightGBM] [Info] Number of data points in the train set: 2603, number of used features: 25\n",
      "[LightGBM] [Info] Start training from score 130.398183\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000548 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5631\n",
      "[LightGBM] [Info] Number of data points in the train set: 2603, number of used features: 24\n",
      "[LightGBM] [Info] Start training from score 130.398183\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000394 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5376\n",
      "[LightGBM] [Info] Number of data points in the train set: 2603, number of used features: 23\n",
      "[LightGBM] [Info] Start training from score 130.398183\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001452 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5366\n",
      "[LightGBM] [Info] Number of data points in the train set: 2603, number of used features: 22\n",
      "[LightGBM] [Info] Start training from score 130.398183\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000454 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5111\n",
      "[LightGBM] [Info] Number of data points in the train set: 2603, number of used features: 21\n",
      "[LightGBM] [Info] Start training from score 130.398183\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000411 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4856\n",
      "[LightGBM] [Info] Number of data points in the train set: 2603, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 130.398183\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000590 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4601\n",
      "[LightGBM] [Info] Number of data points in the train set: 2603, number of used features: 19\n",
      "[LightGBM] [Info] Start training from score 130.398183\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000394 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4346\n",
      "[LightGBM] [Info] Number of data points in the train set: 2603, number of used features: 18\n",
      "[LightGBM] [Info] Start training from score 130.398183\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000617 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4091\n",
      "[LightGBM] [Info] Number of data points in the train set: 2603, number of used features: 17\n",
      "[LightGBM] [Info] Start training from score 130.398183\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000325 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4080\n",
      "[LightGBM] [Info] Number of data points in the train set: 2603, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 130.398183\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3825\n",
      "[LightGBM] [Info] Number of data points in the train set: 2603, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 130.398183\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000506 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 2603, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 130.398183\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000518 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3315\n",
      "[LightGBM] [Info] Number of data points in the train set: 2603, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 130.398183\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000241 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3060\n",
      "[LightGBM] [Info] Number of data points in the train set: 2603, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score 130.398183\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 2603, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 130.398183\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000485 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2550\n",
      "[LightGBM] [Info] Number of data points in the train set: 2603, number of used features: 10\n",
      "[LightGBM] [Info] Start training from score 130.398183\n",
      "Selected features are index [ 0 12 14 15 19 20 24 32 38 42]\n"
     ]
    }
   ],
   "source": [
    "X_train_selected, X_test_selected = fs.perform_feature_selection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_indices = [0, 12, 14, 15, 19, 20, 24, 32, 38, 42]\n",
    "\n",
    "# Get column names corresponding to selected indices\n",
    "selected_columns = X_train_selected.columns[selected_indices]\n",
    "\n",
    "# Print the selected column names\n",
    "print(\"Selected columns:\", selected_columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_converted, y_test_converted = fs.convert_y_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = lstm(X_train_selected, y_train, X_test_selected, y_test, units=64, epochs=1000, batch_size=16, patience=50, monitor='val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model built and compiled.\n"
     ]
    }
   ],
   "source": [
    "ls.build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "163/163 [==============================] - 23s 49ms/step - loss: 16051.5078 - val_loss: 31446.8926\n",
      "Epoch 2/1000\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 15024.5303 - val_loss: 30554.1797\n",
      "Epoch 3/1000\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 14326.7168 - val_loss: 29551.7793\n",
      "Epoch 4/1000\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 13672.9326 - val_loss: 28626.6016\n",
      "Epoch 5/1000\n",
      "163/163 [==============================] - 5s 28ms/step - loss: 13049.0098 - val_loss: 27819.3770\n",
      "Epoch 6/1000\n",
      "163/163 [==============================] - 5s 28ms/step - loss: 12450.2363 - val_loss: 27057.0332\n",
      "Epoch 7/1000\n",
      "163/163 [==============================] - 5s 28ms/step - loss: 11873.7764 - val_loss: 26306.3105\n",
      "Epoch 8/1000\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 11318.0781 - val_loss: 25535.2520\n",
      "Epoch 9/1000\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 10782.0674 - val_loss: 24747.9238\n",
      "Epoch 10/1000\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 10264.7041 - val_loss: 23912.5469\n",
      "Epoch 11/1000\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 9765.1680 - val_loss: 22979.0918\n",
      "Epoch 12/1000\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 9282.9199 - val_loss: 21967.7949\n",
      "Epoch 13/1000\n",
      "163/163 [==============================] - 6s 34ms/step - loss: 8817.1709 - val_loss: 20970.7285\n",
      "Epoch 14/1000\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 8367.6338 - val_loss: 20027.2930\n",
      "Epoch 15/1000\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 7933.8540 - val_loss: 19164.9121\n",
      "Epoch 16/1000\n",
      "163/163 [==============================] - 5s 31ms/step - loss: 7515.3716 - val_loss: 18367.1406\n",
      "Epoch 17/1000\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 7111.8296 - val_loss: 17669.1152\n",
      "Epoch 18/1000\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 6722.8423 - val_loss: 17033.1348\n",
      "Epoch 19/1000\n",
      "163/163 [==============================] - 7s 44ms/step - loss: 6348.1694 - val_loss: 16423.5527\n",
      "Epoch 20/1000\n",
      "163/163 [==============================] - 6s 38ms/step - loss: 5987.4302 - val_loss: 15831.7637\n",
      "Epoch 21/1000\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 5640.2944 - val_loss: 15256.3926\n",
      "Epoch 22/1000\n",
      "163/163 [==============================] - 4s 26ms/step - loss: 5306.6895 - val_loss: 14696.7002\n",
      "Epoch 23/1000\n",
      "163/163 [==============================] - 4s 26ms/step - loss: 4986.2852 - val_loss: 14151.6396\n",
      "Epoch 24/1000\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 4678.7354 - val_loss: 13621.7627\n",
      "Epoch 25/1000\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 4383.9351 - val_loss: 13105.5791\n",
      "Epoch 26/1000\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 4101.7422 - val_loss: 12604.5225\n",
      "Epoch 27/1000\n",
      "163/163 [==============================] - 5s 30ms/step - loss: 3831.8887 - val_loss: 12117.6396\n",
      "Epoch 28/1000\n",
      "163/163 [==============================] - 5s 31ms/step - loss: 3574.1614 - val_loss: 11643.8564\n",
      "Epoch 29/1000\n",
      "163/163 [==============================] - 5s 31ms/step - loss: 3328.3035 - val_loss: 11184.1309\n",
      "Epoch 30/1000\n",
      "163/163 [==============================] - 5s 29ms/step - loss: 3094.3193 - val_loss: 10738.1904\n",
      "Epoch 31/1000\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 2871.8970 - val_loss: 10306.0596\n",
      "Epoch 32/1000\n",
      "163/163 [==============================] - 5s 31ms/step - loss: 2660.7515 - val_loss: 9887.5605\n",
      "Epoch 33/1000\n",
      "163/163 [==============================] - 5s 30ms/step - loss: 2460.8237 - val_loss: 9481.7031\n",
      "Epoch 34/1000\n",
      "163/163 [==============================] - 5s 31ms/step - loss: 2271.8550 - val_loss: 9089.2383\n",
      "Epoch 35/1000\n",
      "163/163 [==============================] - 5s 31ms/step - loss: 2093.7725 - val_loss: 8710.4199\n",
      "Epoch 36/1000\n",
      "163/163 [==============================] - 5s 30ms/step - loss: 1926.2184 - val_loss: 8344.9893\n",
      "Epoch 37/1000\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 1769.0480 - val_loss: 7990.9634\n",
      "Epoch 38/1000\n",
      "163/163 [==============================] - 10s 63ms/step - loss: 1622.0463 - val_loss: 7651.1333\n",
      "Epoch 39/1000\n",
      "163/163 [==============================] - 6s 34ms/step - loss: 1484.8308 - val_loss: 7324.7363\n",
      "Epoch 40/1000\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 1357.2788 - val_loss: 7009.4897\n",
      "Epoch 41/1000\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 1239.1796 - val_loss: 6707.7456\n",
      "Epoch 42/1000\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 1130.1927 - val_loss: 6419.3438\n",
      "Epoch 43/1000\n",
      "163/163 [==============================] - 5s 31ms/step - loss: 1030.1136 - val_loss: 6141.2393\n",
      "Epoch 44/1000\n",
      "163/163 [==============================] - 5s 31ms/step - loss: 938.5192 - val_loss: 5877.6348\n",
      "Epoch 45/1000\n",
      "163/163 [==============================] - 5s 31ms/step - loss: 855.2491 - val_loss: 5624.9268\n",
      "Epoch 46/1000\n",
      "163/163 [==============================] - 5s 30ms/step - loss: 779.9478 - val_loss: 5385.0581\n",
      "Epoch 47/1000\n",
      "163/163 [==============================] - 5s 31ms/step - loss: 712.2835 - val_loss: 5157.8066\n",
      "Epoch 48/1000\n",
      "163/163 [==============================] - 5s 30ms/step - loss: 651.8769 - val_loss: 4943.9575\n",
      "Epoch 49/1000\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 598.2963 - val_loss: 4739.6558\n",
      "Epoch 50/1000\n",
      "163/163 [==============================] - 6s 34ms/step - loss: 551.2231 - val_loss: 4548.7964\n",
      "Epoch 51/1000\n",
      "163/163 [==============================] - 5s 31ms/step - loss: 510.3483 - val_loss: 4369.5396\n",
      "Epoch 52/1000\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 474.9720 - val_loss: 4203.6274\n",
      "Epoch 53/1000\n",
      "163/163 [==============================] - 10s 62ms/step - loss: 444.8311 - val_loss: 4047.1089\n",
      "Epoch 54/1000\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 419.5084 - val_loss: 3902.8572\n",
      "Epoch 55/1000\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 398.4950 - val_loss: 3771.7998\n",
      "Epoch 56/1000\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 381.2468 - val_loss: 3652.5300\n",
      "Epoch 57/1000\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 367.3225 - val_loss: 3542.9995\n",
      "Epoch 58/1000\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 356.3766 - val_loss: 3444.3411\n",
      "Epoch 59/1000\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 347.8865 - val_loss: 3356.9714\n",
      "Epoch 60/1000\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 341.3798 - val_loss: 3277.4062\n",
      "Epoch 61/1000\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 336.5950 - val_loss: 3211.4558\n",
      "Epoch 62/1000\n",
      "163/163 [==============================] - 10s 64ms/step - loss: 333.2388 - val_loss: 3151.0715\n",
      "Epoch 63/1000\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 330.8392 - val_loss: 3102.6741\n",
      "Epoch 64/1000\n",
      "163/163 [==============================] - 6s 37ms/step - loss: 329.2068 - val_loss: 3064.3291\n",
      "Epoch 65/1000\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 328.1220 - val_loss: 3027.6475\n",
      "Epoch 66/1000\n",
      "163/163 [==============================] - 10s 64ms/step - loss: 327.4392 - val_loss: 2999.1746\n",
      "Epoch 67/1000\n",
      "163/163 [==============================] - 8s 48ms/step - loss: 327.0437 - val_loss: 2977.2429\n",
      "Epoch 68/1000\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 326.7949 - val_loss: 2961.8442\n",
      "Epoch 69/1000\n",
      "163/163 [==============================] - 6s 39ms/step - loss: 326.6702 - val_loss: 2948.8706\n",
      "Epoch 70/1000\n",
      "163/163 [==============================] - 10s 60ms/step - loss: 326.5583 - val_loss: 2936.3743\n",
      "Epoch 71/1000\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 326.5377 - val_loss: 2932.9822\n",
      "Epoch 72/1000\n",
      "163/163 [==============================] - 6s 34ms/step - loss: 326.5049 - val_loss: 2919.8281\n",
      "Epoch 73/1000\n",
      "163/163 [==============================] - 9s 58ms/step - loss: 326.4946 - val_loss: 2920.5947\n",
      "Epoch 74/1000\n",
      "163/163 [==============================] - 5s 33ms/step - loss: 326.4968 - val_loss: 2918.3618\n",
      "Epoch 75/1000\n",
      "163/163 [==============================] - 6s 36ms/step - loss: 326.4952 - val_loss: 2919.1277\n",
      "Epoch 76/1000\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 326.5157 - val_loss: 2917.6140\n",
      "Epoch 77/1000\n",
      "163/163 [==============================] - 11s 67ms/step - loss: 326.5182 - val_loss: 2917.1746\n",
      "Epoch 78/1000\n",
      "163/163 [==============================] - 12s 76ms/step - loss: 326.4979 - val_loss: 2911.7261\n",
      "Epoch 79/1000\n",
      "163/163 [==============================] - 6s 40ms/step - loss: 326.5372 - val_loss: 2918.8042\n",
      "Epoch 80/1000\n",
      "163/163 [==============================] - 7s 44ms/step - loss: 326.5975 - val_loss: 2908.9043\n",
      "Epoch 81/1000\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 326.6285 - val_loss: 4553.0264\n",
      "Epoch 82/1000\n",
      "163/163 [==============================] - 10s 60ms/step - loss: 322.4606 - val_loss: 4804.0654\n",
      "Epoch 83/1000\n",
      "163/163 [==============================] - 5s 30ms/step - loss: 287.9962 - val_loss: 17791.9551\n",
      "Epoch 84/1000\n",
      "163/163 [==============================] - 6s 35ms/step - loss: 234.8107 - val_loss: 18497.4062\n",
      "Epoch 85/1000\n",
      "163/163 [==============================] - 5s 32ms/step - loss: 195.3885 - val_loss: 10333.1367\n",
      "Epoch 86/1000\n",
      "119/163 [====================>.........] - ETA: 2s - loss: 177.5606"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joyri\\OneDrive\\Documents\\Capstone Prep Final Project\\AIGC-5005-0NA-Final-Project\\src\\lstm.py:42\u001b[0m, in \u001b[0;36mlstm.train_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     39\u001b[0m X_train_reshaped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhistory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train_reshaped\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel training completed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\joyri\\anaconda3\\envs\\py-torch-tf-env\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\joyri\\anaconda3\\envs\\py-torch-tf-env\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\joyri\\anaconda3\\envs\\py-torch-tf-env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\joyri\\anaconda3\\envs\\py-torch-tf-env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\joyri\\anaconda3\\envs\\py-torch-tf-env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\joyri\\anaconda3\\envs\\py-torch-tf-env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\joyri\\anaconda3\\envs\\py-torch-tf-env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\joyri\\anaconda3\\envs\\py-torch-tf-env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\joyri\\anaconda3\\envs\\py-torch-tf-env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ls.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py-torch-tf-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
